{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This notebooks shows the struture of the network/the loss functions/the training of our approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n",
    "\n",
    "# The data below can be downloaded from: https://drive.google.com/drive/folders/1IoxOtAt-8NiFgbtZh1RDY32Jb_Wd5TGa?usp=sharing\n",
    "\n",
    "signals_train=np.load('signals_train.npy')\n",
    "distributions_train=np.load('distributions_train.npy')\n",
    "signals_valid=np.load('signals_valid.npy')\n",
    "distributions_valid=np.load('distributions_valid.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "#Define Loss functions\n",
    "\n",
    "arr=np.logspace(math.log10(10.0), math.log10(2000.), num=60, endpoint=True, base=10.0)\n",
    "\n",
    "arr=np.tile(arr, (2000, 1))\n",
    "\n",
    "arr_tf=tf.constant(arr.astype('float32'), dtype=tf.float32)\n",
    "\n",
    "\n",
    "#Implementation of the Wasserstein Distance\n",
    "def wasserstein_distance(y_actual,y_pred):\n",
    "    #np.abs(np.cumsum(gt_distributions[40,:]-dist_array[40,:])\n",
    "           \n",
    "    abs_cdf_difference=tf.math.abs(tf.math.cumsum(y_actual-y_pred,axis=1))\n",
    "\n",
    "    return tf.reduce_mean(0.5*tf.reduce_sum(tf.math.multiply(-arr_tf[:,:-1]+arr_tf[:,1:],abs_cdf_difference[:,:-1]+abs_cdf_difference[:,1:]),axis=1))\n",
    "\n",
    "#Combination loss function used in MIML\n",
    "def MSE_wasserstein_combo(y_actual,y_pred):\n",
    "    wass_loss=wasserstein_distance(y_actual,y_pred)\n",
    "    MSE= tf.math.reduce_mean(tf.reduce_mean(tf.math.squared_difference(y_pred, y_actual),axis=1))\n",
    "    return wass_loss+100000.*MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the network structure\n",
    "inputs = tf.keras.Input(shape=(32,))\n",
    "x = tf.keras.layers.Dense(256, activation=tf.nn.leaky_relu, kernel_initializer='he_uniform',bias_initializer=tf.keras.initializers.Constant(0.01))(inputs)\n",
    "x = tf.keras.layers.Dense(256, activation=tf.nn.leaky_relu, kernel_initializer='he_uniform',bias_initializer=tf.keras.initializers.Constant(0.01))(x)\n",
    "x=tf.keras.layers.Dense(256, activation=tf.nn.leaky_relu, kernel_initializer='he_uniform',bias_initializer=tf.keras.initializers.Constant(0.01))(x)\n",
    "x=tf.keras.layers.Dense(256, activation=tf.nn.leaky_relu, kernel_initializer='he_uniform',bias_initializer=tf.keras.initializers.Constant(0.01))(x)\n",
    "x=tf.keras.layers.Dense(256, activation=tf.nn.leaky_relu, kernel_initializer='he_uniform',bias_initializer=tf.keras.initializers.Constant(0.01))(x)\n",
    "x=tf.keras.layers.Dense(256, activation=tf.nn.leaky_relu, kernel_initializer='he_uniform',bias_initializer=tf.keras.initializers.Constant(0.01))(x)\n",
    "outputs=tf.keras.layers.Dense(60, activation=tf.keras.activations.softmax, kernel_initializer='he_uniform',bias_initializer=tf.keras.initializers.Constant(0.01))(x)\n",
    "#outputs=tf.keras.layers.Dense(2, activation=tf.keras.activations.relu, kernel_initializer='normal',bias_initializer=tf.keras.initializers.Constant(0.1))(x)\n",
    "#outputs=tf.clip_by_value(x,90.,180.)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1120000 samples, validate on 140000 samples\n",
      "Epoch 1/30\n",
      "1120000/1120000 [==============================] - 3s 3us/sample - loss: 304.6825 - mse: 0.0019 - wasserstein_distance: 113.6731 - val_loss: 203.3446 - val_mse: 0.0013 - val_wasserstein_distance: 72.0536\n",
      "Epoch 2/30\n",
      "1120000/1120000 [==============================] - 2s 2us/sample - loss: 194.8253 - mse: 0.0013 - wasserstein_distance: 68.5057 - val_loss: 166.2103 - val_mse: 0.0011 - val_wasserstein_distance: 60.2232\n",
      "Epoch 3/30\n",
      "1120000/1120000 [==============================] - 2s 2us/sample - loss: 174.9863 - mse: 0.0011 - wasserstein_distance: 61.9019 - val_loss: 162.0262 - val_mse: 0.0010 - val_wasserstein_distance: 57.1786\n",
      "Epoch 4/30\n",
      "1120000/1120000 [==============================] - 2s 2us/sample - loss: 164.0099 - mse: 0.0011 - wasserstein_distance: 58.6505 - val_loss: 160.4417 - val_mse: 0.0010 - val_wasserstein_distance: 56.9322\n",
      "Epoch 5/30\n",
      "1120000/1120000 [==============================] - 2s 2us/sample - loss: 149.3295 - mse: 9.4137e-04 - wasserstein_distance: 55.1925 - val_loss: 135.8522 - val_mse: 8.4267e-04 - val_wasserstein_distance: 51.5856\n",
      "Epoch 6/30\n",
      "1120000/1120000 [==============================] - 2s 2us/sample - loss: 135.6677 - mse: 8.4021e-04 - wasserstein_distance: 51.6463 - val_loss: 125.5222 - val_mse: 7.5943e-04 - val_wasserstein_distance: 49.5797\n",
      "Epoch 7/30\n",
      "1120000/1120000 [==============================] - 2s 2us/sample - loss: 130.1415 - mse: 8.0118e-04 - wasserstein_distance: 50.0234 - val_loss: 120.4239 - val_mse: 7.3576e-04 - val_wasserstein_distance: 46.8475\n",
      "Epoch 8/30\n",
      "1120000/1120000 [==============================] - 2s 2us/sample - loss: 126.5883 - mse: 7.7726e-04 - wasserstein_distance: 48.8619 - val_loss: 128.3097 - val_mse: 7.9478e-04 - val_wasserstein_distance: 48.8321\n",
      "Epoch 9/30\n",
      "1120000/1120000 [==============================] - 2s 2us/sample - loss: 130.4670 - mse: 8.0434e-04 - wasserstein_distance: 50.0332 - val_loss: 143.6337 - val_mse: 9.2172e-04 - val_wasserstein_distance: 51.4617\n",
      "Epoch 10/30\n",
      "1120000/1120000 [==============================] - 2s 2us/sample - loss: 123.7163 - mse: 7.5789e-04 - wasserstein_distance: 47.9269 - val_loss: 121.8955 - val_mse: 7.3812e-04 - val_wasserstein_distance: 48.0839\n",
      "Epoch 11/30\n",
      "1120000/1120000 [==============================] - 2s 2us/sample - loss: 125.6941 - mse: 7.7155e-04 - wasserstein_distance: 48.5394 - val_loss: 119.9019 - val_mse: 7.3527e-04 - val_wasserstein_distance: 46.3748\n",
      "Epoch 12/30\n",
      "1120000/1120000 [==============================] - 2s 2us/sample - loss: 122.8301 - mse: 7.5012e-04 - wasserstein_distance: 47.8182 - val_loss: 161.6341 - val_mse: 0.0010 - val_wasserstein_distance: 58.4095\n",
      "Epoch 13/30\n",
      "1120000/1120000 [==============================] - 2s 2us/sample - loss: 120.4230 - mse: 7.3383e-04 - wasserstein_distance: 47.0399 - val_loss: 112.8008 - val_mse: 6.7609e-04 - val_wasserstein_distance: 45.1922\n",
      "Epoch 14/30\n",
      "1120000/1120000 [==============================] - 2s 2us/sample - loss: 121.4780 - mse: 7.4181e-04 - wasserstein_distance: 47.2968 - val_loss: 120.9488 - val_mse: 7.4236e-04 - val_wasserstein_distance: 46.7124\n",
      "Epoch 15/30\n",
      "1120000/1120000 [==============================] - 2s 2us/sample - loss: 116.6961 - mse: 7.0931e-04 - wasserstein_distance: 45.7655 - val_loss: 119.2037 - val_mse: 7.2600e-04 - val_wasserstein_distance: 46.6035\n",
      "Epoch 16/30\n",
      "1120000/1120000 [==============================] - 3s 2us/sample - loss: 115.8171 - mse: 7.0310e-04 - wasserstein_distance: 45.5070 - val_loss: 111.6490 - val_mse: 6.7526e-04 - val_wasserstein_distance: 44.1232\n",
      "Epoch 17/30\n",
      "1120000/1120000 [==============================] - 2s 2us/sample - loss: 115.4857 - mse: 7.0149e-04 - wasserstein_distance: 45.3366 - val_loss: 118.6166 - val_mse: 7.2481e-04 - val_wasserstein_distance: 46.1352\n",
      "Epoch 18/30\n",
      "1120000/1120000 [==============================] - 2s 2us/sample - loss: 116.1036 - mse: 7.0514e-04 - wasserstein_distance: 45.5899 - val_loss: 109.0633 - val_mse: 6.5176e-04 - val_wasserstein_distance: 43.8868\n",
      "Epoch 19/30\n",
      "1120000/1120000 [==============================] - 2s 2us/sample - loss: 113.2248 - mse: 6.8614e-04 - wasserstein_distance: 44.6104 - val_loss: 121.8138 - val_mse: 7.3011e-04 - val_wasserstein_distance: 48.8026\n",
      "Epoch 20/30\n",
      "1120000/1120000 [==============================] - 2s 2us/sample - loss: 112.7657 - mse: 6.8327e-04 - wasserstein_distance: 44.4384 - val_loss: 108.6189 - val_mse: 6.5340e-04 - val_wasserstein_distance: 43.2785\n",
      "Epoch 21/30\n",
      "1120000/1120000 [==============================] - 2s 2us/sample - loss: 115.1941 - mse: 7.0074e-04 - wasserstein_distance: 45.1202 - val_loss: 108.9597 - val_mse: 6.6152e-04 - val_wasserstein_distance: 42.8079\n",
      "Epoch 22/30\n",
      "1120000/1120000 [==============================] - 2s 2us/sample - loss: 113.1861 - mse: 6.8646e-04 - wasserstein_distance: 44.5399 - val_loss: 109.5884 - val_mse: 6.6365e-04 - val_wasserstein_distance: 43.2229\n",
      "Epoch 23/30\n",
      "1120000/1120000 [==============================] - 2s 2us/sample - loss: 112.6004 - mse: 6.8277e-04 - wasserstein_distance: 44.3232 - val_loss: 109.3601 - val_mse: 6.6226e-04 - val_wasserstein_distance: 43.1341\n",
      "Epoch 24/30\n",
      "1120000/1120000 [==============================] - 2s 2us/sample - loss: 113.3165 - mse: 6.8763e-04 - wasserstein_distance: 44.5540 - val_loss: 110.3811 - val_mse: 6.6928e-04 - val_wasserstein_distance: 43.4534\n",
      "Epoch 25/30\n",
      "1120000/1120000 [==============================] - 2s 2us/sample - loss: 113.0691 - mse: 6.8600e-04 - wasserstein_distance: 44.4692 - val_loss: 110.9857 - val_mse: 6.6791e-04 - val_wasserstein_distance: 44.1944\n",
      "Epoch 26/30\n",
      "1120000/1120000 [==============================] - 2s 2us/sample - loss: 111.2511 - mse: 6.7390e-04 - wasserstein_distance: 43.8609 - val_loss: 112.8042 - val_mse: 6.7267e-04 - val_wasserstein_distance: 45.5376\n",
      "Epoch 27/30\n",
      "1120000/1120000 [==============================] - 2s 2us/sample - loss: 110.1942 - mse: 6.6670e-04 - wasserstein_distance: 43.5242 - val_loss: 106.2750 - val_mse: 6.3926e-04 - val_wasserstein_distance: 42.3489\n",
      "Epoch 28/30\n",
      "1120000/1120000 [==============================] - 2s 2us/sample - loss: 112.1269 - mse: 6.8038e-04 - wasserstein_distance: 44.0887 - val_loss: 108.8951 - val_mse: 6.5415e-04 - val_wasserstein_distance: 43.4798\n",
      "Epoch 29/30\n",
      "1120000/1120000 [==============================] - 2s 2us/sample - loss: 111.1544 - mse: 6.7351e-04 - wasserstein_distance: 43.8031 - val_loss: 106.7430 - val_mse: 6.3840e-04 - val_wasserstein_distance: 42.9029\n",
      "Epoch 30/30\n",
      "1120000/1120000 [==============================] - 2s 2us/sample - loss: 110.7292 - mse: 6.7066e-04 - wasserstein_distance: 43.6629 - val_loss: 107.3873 - val_mse: 6.4729e-04 - val_wasserstein_distance: 42.6581\n",
      "Time Elapsed:71 seconds\n"
     ]
    }
   ],
   "source": [
    "#Define optimizer and train the network\n",
    "\n",
    "# checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "#     'weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', verbose=0, save_best_only=False,\n",
    "#     save_weights_only=True, mode='auto', save_freq='epoch'\n",
    "# )\n",
    "\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt,\n",
    "              \n",
    "              loss=MSE_wasserstein_combo,metrics=['mse',wasserstein_distance])\n",
    "start=time.time()\n",
    "\n",
    "model.fit(signals_train, distributions_train,epochs=30, batch_size=2000, validation_data=(signals_valid,distributions_valid))  # starts training\n",
    "\n",
    "#To save the model for each epoch, uncomment the checkpoint_callback above and use\n",
    "#model.fit(signals_train, distributions_train,epochs=30, batch_size=2000, validation_data=(signals_valid,distributions_valid),callbacks=[checkpoint_callback])  # starts training\n",
    "\n",
    "\n",
    "end=time.time()\n",
    "\n",
    "print('Time Elapsed:%i seconds'%(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
